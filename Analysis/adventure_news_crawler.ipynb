{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758bfd38",
   "metadata": {},
   "source": [
    "# 네이버 뉴스 크롤링 코드 (기능)\n",
    "## 요구 사항\n",
    "### - 지역명 입력 받아 글자 잘라서 자동 검색 되도록\n",
    "####    - 예: 경상북도 안동시 -> 안동 / 경상남도 창원시 마산합포구 -> 마산합포\n",
    "### - 구현 파트에 크롤링 결과를 어떤 형태로 넘겨줘야 하는지 상의 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5077e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup     \n",
    "import pandas as pd   \n",
    "import openpyxl\n",
    "import urllib.request\n",
    "import urllib\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "# 사용자로부터 입력 받기\n",
    "query_txt = input('키워드 : ')\n",
    "cnt=int(input('데이터 건 수: ') )\n",
    "page_cnt = math.ceil(cnt / 10)\n",
    "\n",
    "f_dir = input('저장 경로 (예:c:\\\\py_temp\\\\): ')\n",
    "if f_dir =='' :\n",
    "        f_dir = \"c:\\\\py_temp\\\\\" + query_txt + '\\\\'\n",
    "#fc_name=input('csv 저장 경로와 파일명(예:c:\\\\py_temp\\\\naver.csv): ')\n",
    "#fx_name=input('xls 저장 경로와 파일명(예:c:\\\\py_temp\\\\naver.xls): ')\n",
    "fc_name = f_dir + 'Naver news' + query_txt + '.csv'\n",
    "fx_name = f_dir + 'Naver news' + query_txt + '.xls'\n",
    "print('=' *100)\n",
    "\n",
    "# 네이버 접속 -> 뉴스 페이지로 이동\n",
    "url = 'https://www.naver.com'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "s_time = time.time( )\n",
    "element = driver.find_element(By.ID,'query')\n",
    "driver.find_element(By.ID,'query').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "driver.find_element(By.LINK_TEXT,'뉴스').click( )\n",
    "time.sleep(1)\n",
    "driver.find_element(By.LINK_TEXT, '옵션').click()\n",
    "time.sleep(1)\n",
    "driver.find_element(By.LINK_TEXT, '보도자료').click()\n",
    "\n",
    "# 저장할 리스트\n",
    "title2 = []        # 제목\n",
    "img_src2=[]         # 이미지\n",
    "url_all_list=[]    # URL\n",
    "\n",
    "img_dir = f_dir + ' photo' + '\\\\' # 이미지는 csv, xls 파일이 저장된 폴더 내의 photo라는 폴더 내에 저장\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "no = 1\n",
    "\n",
    "# 크롤링\n",
    "for a in range(1, page_cnt + 1) :\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    news_list = soup.find('ul','list_news').find_all('li')\n",
    "        \n",
    "    for i in news_list:\n",
    "        try:\n",
    "            lump = i.find('div','news_area').find_all('a') \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        img_src = i.find_all('img')\n",
    "\n",
    "        url_all_list.append(lump[5]['href'])\n",
    "        print('주소:', lump[5]['href'])\n",
    "        \n",
    "        title = lump[4].get_text()              # 게시물 제목\n",
    "        if title == '네이버뉴스':\n",
    "            title = lump[5].get_text()\n",
    "        title2.append(title)                       # 게시물 제목 리스트에 추가\n",
    "        print('제목:',title)\n",
    "        \n",
    "        img_src1 = img_src[1]['src']\n",
    "        if 'http' in img_src1 : # 찾는 이미지는 http로 시작하는 이미지인데 이렇게 시작하지 않는 이미지(예를 들어 버튼..)은 거르기 위해 이 if문 사용\n",
    "            img_src2.append(img_src1)\n",
    "            \n",
    "        print('이미지:', img_src1)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        no += 1\n",
    "        \n",
    "        if no > cnt :\n",
    "            break\n",
    "\n",
    "file_no = 1\n",
    "for i in range(0,len(img_src2)) :\n",
    "        try :\n",
    "                urllib.request.urlretrieve(img_src2[i],str(file_no)+'.jpg')\n",
    "        except :\n",
    "                continue        \n",
    "        time.sleep(0.5)      \n",
    "        file_no += 1  \n",
    "        if file_no > cnt :\n",
    "            break\n",
    "            \n",
    "# 출력 결과를 표(데이터 프레임) 형태로 만들기\n",
    "naver_news = pd.DataFrame()\n",
    "naver_news['제목'] = title2\n",
    "#naver_news['사진'] = img_src2\n",
    "naver_news['주소'] = url_all_list\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "naver_news.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "print(\" csv 파일 저장 경로: %s\" %fc_name) \n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "naver_news.to_excel(fx_name , index=False , encoding=\"UTF-8\" , engine='openpyxl')\n",
    "print(\" xls 파일 저장 경로: %s\" %fx_name) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
